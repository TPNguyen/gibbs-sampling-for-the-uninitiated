{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibbs Sampling for the Uninitiated with Python \n",
    "\n",
    "The tutorial paper \n",
    "[Gibbs Sampling for the Uninitiated](https://www.umiacs.umd.edu/~resnik/pubs/LAMP-TR-153.pdf)\n",
    "by Resnik and Hardisty is a masterpiece of exposition.  Their main example provides an amazingly \n",
    "clear description of how to build a Gibbs sampler for the very simple Naı̈ve Bayes probabilistic model. In this post I will implement that sampler in Python and exercise the implementation with a simulated text classification problem. To make things as easy to follow as possible, I'll ignore optimizing the code.  In a follow-up post I'll discuss optimization.\n",
    "\n",
    "The diagram below illustrates the problem to be solved.  There is a collection documents, some with labels and \n",
    "some without.  The goal is to predict the labels for the unlabelled documents based on those we do observe.\n",
    "\n",
    "![Graphical Model](https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-01/fc024fbdc59c3b5e708268b29e00cebaf9593875/8-Figure4-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State space and initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the latent variable $\\pi$ can be integrated out (see $\\S$2.4.3 of the paper), the state of the model at an\n",
    "interation step is determined by the current values for the predicted labels $\\bf L$, \n",
    "the topics $\\bf \\theta_0$ and $\\bf \\theta_1$, for each word $i$, the number of times, $N_{x,i}$, \n",
    "it occurs in the set of all documents labeled $x$, the number of documents labelled $0$, $C_0$, and \n",
    "the number of documents labelled $1$, $C_1$.  In the code below, this state will be represented as a dictionary\n",
    "with the following keys: 'L' for the predicted labels, 'theta' for the topics, 'cnts' for word counts and 'C' \n",
    "for document counts.\n",
    "\n",
    "How to initialize our sampler is described in at the end of $\\S$2.3 of the paper:\n",
    "1. Pick a value $\\pi$ by sampling from the Beta($\\gamma_{\\pi1}$, $\\gamma_{\\pi0}$) distribution. \n",
    "2. Then, for each $j$, flip a coin with success probability $\\pi$, and assign the label $L_j$ of document \n",
    "   $j$ based on the outcome of the coin flip.\n",
    "3. Pick values for $\\theta_0$ and $\\theta_1$ by sampling from Dirichlet($\\gamma_{\\theta}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import beta, binomial, dirichlet\n",
    "\n",
    "def sample_labels(J, gamma_pi):\n",
    "    pi = beta(gamma_pi[0], gamma_pi[1])\n",
    "    return binomial(1, pi, J)\n",
    "\n",
    "def initialize(W, labels, gamma_pi, gamma_theta):\n",
    "    N = len(W)\n",
    "    M = len(labels)\n",
    "    V = len(gamma_theta)\n",
    "\n",
    "    L = sample_labels(N - M, gamma_pi)\n",
    "    theta = dirichlet(gamma_theta, 2)\n",
    "\n",
    "    C = np.zeros((2,))\n",
    "    C += gamma_pi\n",
    "    cnts = np.zeros((2, V))\n",
    "    cnts += gamma_theta\n",
    "    \n",
    "    for d, l in zip(W, labels.tolist() + L.tolist()):\n",
    "        for i, c in d: cnts[l][i] += c\n",
    "        C[l] += 1\n",
    "\n",
    "    return {'C':C, 'N':cnts, 'L':L, 'theta':theta}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The update step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update(state, X):\n",
    "    C = state['C']\n",
    "    N = state['N']\n",
    "    L = state['L']\n",
    "    theta = state['theta']\n",
    "    # Update the labels for all documents:\n",
    "    for j, l in enumerate(L):\n",
    "        # Drop document j from the corpus:\n",
    "        for i, c in X[j]: N[l][i] -= c\n",
    "        C[l] -= 1  \n",
    "        # Compute the conditional probability that L[j] = 1:  \n",
    "        if C[0] == 1: pi = 1.0\n",
    "        elif C[1] == 1 <= 0: pi = 0.0 \n",
    "        else:\n",
    "            # compute the product of probabilities (sum of logs)\n",
    "            d = np.sum(C) - 1\n",
    "            v0 = np.log((C[0] - 1.0) / d)\n",
    "            v1 = np.log((C[1] - 1.0) / d)\n",
    "            for i, c in X[j]:\n",
    "                v0 += c * np.log(theta[0,i])\n",
    "                v1 += c * np.log(theta[1,i])\n",
    "            m = max(v0, v1)\n",
    "            v0 = np.exp(v0 - m)\n",
    "            v1 = np.exp(v1 - m)\n",
    "            pi = v1 / (v0 + v1)\n",
    "        # Sample the new label from the conditional probability:\n",
    "        l = binomial(1, pi)\n",
    "        L[j] = l\n",
    "        # Add document j back into the corpus:\n",
    "        C[l] += 1\n",
    "        for i, c in X[j]: N[l][i] += c\n",
    "    #print('--->>>', np.min(cnts[0]), np.min(cnts[1]))\n",
    "    # Update the topics:\n",
    "    theta[0] = dirichlet(N[0])\n",
    "    theta[1] = dirichlet(N[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_sampler(W, labels, iterations, gamma_pi, gamma_theta):\n",
    "    state = initialize(W, labels, gamma_pi, gamma_theta)\n",
    "    X = W[len(labels):]\n",
    "    for t in range(iterations): update(state, X)\n",
    "    return state['L']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.random import multinomial, poisson\n",
    "\n",
    "def generate_data(N, gamma_pi, gamma_theta, lmbda):\n",
    "    labels = sample_labels(N, gamma_pi)\n",
    "    theta = dirichlet(gamma_theta, 2)\n",
    "    W = []\n",
    "    for l in labels:\n",
    "        R = poisson(lmbda)\n",
    "        doc = multinomial(R, theta[l])\n",
    "        W.append({(i, c) for i,c in enumerate(doc) if c > 0})\n",
    "    return W, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(L_true, L_predicted):\n",
    "    correct = 0\n",
    "    for i, l in enumerate(L_predicted):\n",
    "        if L_true[i] == l: correct += 1\n",
    "    accuracy = float(correct)/len(L_predicted)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_simulation(V, N, gamma_pi, gamma_theta, lmbda):\n",
    "    W, labels = generate_data(N, gamma_pi, gamma_theta, lmbda)\n",
    "    iterations = 100\n",
    "    n = int(N * 0.8)\n",
    "    labels_observed = labels[:n]\n",
    "    labels_unobserved = labels[n:]\n",
    "    \n",
    "    L = run_sampler(W, labels_observed, iterations, gamma_pi, gamma_theta)\n",
    "    return compute_accuracy(labels_unobserved, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy results: 0.850, 0.900, 0.800, 0.938, 0.950, 0.963, 0.938, 0.863, 0.738, 0.912\n",
      "Average accuracy = 0.885\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAACz1JREFUeJzt3U+IXed9x+HvTzHuoiTGrsFQOfbCjjENTUNphRZd3Mal\nlrNR6aayIVBDQYsodFcli+JrKLTZldS0QSBcsggKNF2oJSUuJZfiJnFUiOOWSpbcgiLJxiW1E2gg\noIpfF3MR4/H8uaO50sw7fh4Yc88975zzCsyHw3vuuVPdHQDGdGC3JwDArRNxgIGJOMDARBxgYCIO\nMDARBxjYlhGvqtNV9XZVvbbJmC9V1aWqerWqPrncKQKwkUWuxF9M8uRGO6vqqSSPdPfHkhxP8uUl\nzQ2ALWwZ8e5+Ocm7mww5muQr87GvJLmnqh5YzvQA2Mwy1sQPJrmyavva/D0AbjM3NgEGdtcSjnEt\nyUdXbT84f+99qsoXtQDcgu6u9d5fNOI1/1nP2SSfTfK1qjqc5Mfd/fYmE1nwlHBnTafTTKfT3Z4G\nvE/VRvldIOJV9dUkkyS/UFU/TPJckruTdHef6u5vVNWnq+qNJD9N8uxSZg3AlraMeHc/s8CYE8uZ\nDgDb4cYmzE0mk92eAmxb3ck16qpqa+IA21NVG97YdCUOMDARBxjYMj4nDnvOZh/JWibLg+w2EWdf\nupW4ViWazGgspwAMTMQBBibiAAMTcYCBubHJnnfffcm7m/1ZkiW63R9quffe5J13bu85+GDxxCZ7\n3n761Mh++rdw53hiE2CfEnGAgYk4wMBEHGBgIg4wMB8xZM/r1MZ/4XUwveq/sAwizp5X6X3zsbwq\nCWe5LKcADEzEAQYm4gADE3GAgYk4wMBEHGBgIg4wMBEHGJiIAwzME5sM4Xb/xZ075d57d3sG7Dci\nzp53px6591d3GJHlFICBiTjAwEQcYGAiDjAwEYe5557b7RnA9lXfwdvxVdV38nwA+0FVpbvX/aDt\nQlfiVXWkqi5U1cWqOrnO/o9U1dmqerWq/q2qfn+HcwZgAVteiVfVgSQXkzyR5M0k55Ic6+4Lq8Z8\nIclHuvsLVXV/kteTPNDd/7fmWK7EAbZpp1fih5Jc6u7L3X09yZkkR9eM6SQfnr/+cJL/WRtwAJZv\nkYgfTHJl1fbV+XurvZDkl6rqzSQ/SPKHy5keAJtZ1mP3Tyb5fnd/qqoeSfKPVfWJ7v7ftQOn0+nN\n15PJJJPJZElTgJ2ZTld+YLfNZrPMZrOFxi6yJn44ybS7j8y3P5+ku/uLq8b8fZI/7e5/mW//U5KT\n3f2va45lTZw9y3ensFftdE38XJJHq+rhqro7ybEkZ9eMuZzkt+YneyDJY0n+69anDMAitlxO6e4b\nVXUiyUtZif7p7j5fVcdXdvepJH+S5K+r6rX5r/1Rd79z22YNQBIP+8BNllPYq3b8sA8Ae5OIw5zv\nTmFEllMA9jjLKQD7lIgDDEzEAQYm4gADE3GY870pjMinU2DOwz7sVZt9OmVZ32IIe0rVuv+/L/B7\n2xvvooTdJuLsS+LKB4U1cYCBiTjAwEQcYGAiDjAwEQcYmIgDDEzEAQYm4gADE3GAgYk4wMBEHGBg\nIg4wMBEHGJiIAwxMxAEGJuIAAxNxgIGJOMDARBxgYCIOMDARBxiYiAMMTMQBBibiAANbKOJVdaSq\nLlTVxao6ucGYSVV9v6r+vaq+tdxpArCe6u7NB1QdSHIxyRNJ3kxyLsmx7r6wasw9Sb6d5Le7+1pV\n3d/dP1rnWL3V+QB4r6pKd9d6+xa5Ej+U5FJ3X+7u60nOJDm6ZswzSb7e3deSZL2AA7B8i0T8YJIr\nq7avzt9b7bEk91XVt6rqXFV9ZlkTBGBjdy3xOL+a5FNJfj7Jd6rqO939xpKOD8A6Fon4tSQPrdp+\ncP7ealeT/Ki7f5bkZ1X1z0l+Jcn7Ij6dTm++nkwmmUwm25sxwD43m80ym80WGrvIjc0PJXk9Kzc2\n30ryvSRPd/f5VWMeT/IXSY4k+bkkryT5ve7+jzXHcmMTYJs2u7G55ZV4d9+oqhNJXsrKGvrp7j5f\nVcdXdvep7r5QVd9M8lqSG0lOrQ04AMu35ZX4Uk/mShxg23b6EUMA9igRBxiYiAMMTMQBBibiAAMT\ncYCBiTjAwEQcYGAiDjAwEQcYmIgDDEzEAQYm4gADE3GAgYk4wMBEHGBgIg4wMBEHGJiIAwxMxAEG\nJuIAAxNxgIGJOMDARBxgYCIOMDARBxiYiAMMTMQBBibiAAMTcYCBiTjAwEQcYGAiDjAwEQcYmIgD\nDEzEAQa2UMSr6khVXaiqi1V1cpNxv15V16vqd5c3RQA2smXEq+pAkheSPJnk40merqrHNxj3Z0m+\nuexJArC+Ra7EDyW51N2Xu/t6kjNJjq4z7nNJ/ibJfy9xfgBsYpGIH0xyZdX21fl7N1XVLyb5ne7+\nqyS1vOkBsJll3dj88ySr18qFHOAOuGuBMdeSPLRq+8H5e6v9WpIzVVVJ7k/yVFVd7+6zaw82nU5v\nvp5MJplMJtucMsD+NpvNMpvNFhpb3b35gKoPJXk9yRNJ3kryvSRPd/f5Dca/mOTvuvtv19nXW50P\ngPeqqnT3uiscW16Jd/eNqjqR5KWsLL+c7u7zVXV8ZXefWvsrO54xAAvZ8kp8qSdzJQ6wbZtdiXti\nE2BgIg4wMBEHGJiIAwxMxAEGJuIAAxNxgIGJOMDARBxgYCIOMDARBxiYiAMMTMQBBibiAAMTcYCB\niTjAwEQcYGAiDjAwEQcYmIgDDEzEAQYm4gADE3GAgYk4wMBEHGBgIg4wMBEHGJiIAwxMxAEGJuIA\nAxNxgIGJOMDARBxgYCIOMDARBxiYiAMMbKGIV9WRqrpQVRer6uQ6+5+pqh/Mf16uql9e/lQBWKu6\ne/MBVQeSXEzyRJI3k5xLcqy7L6waczjJ+e7+SVUdSTLt7sPrHKu3Oh8A71VV6e5ab98iV+KHklzq\n7svdfT3JmSRHVw/o7u9290/mm99NcnAnEwZgMYtE/GCSK6u2r2bzSP9Bkn/YyaQAWMxdyzxYVf1m\nkmeT/MZGY6bT6c3Xk8kkk8lkmVMAGN5sNstsNlto7CJr4oezssZ9ZL79+STd3V9cM+4TSb6e5Eh3\n/+cGx7ImDrBNO10TP5fk0ap6uKruTnIsydk1J3goKwH/zEYBB2D5tlxO6e4bVXUiyUtZif7p7j5f\nVcdXdvepJH+c5L4kf1lVleR6dx+6nRMHYIHllKWezHIKwLbtdDkFgD1KxAEGJuIAAxNxgIGJOMDA\nRBxgYCIOMDARBxiYiAMMTMQBBibiAAMTcYCBiTjAwEQcYGAiDjAwEQcYmIgDDEzEAQYm4gADE3GA\ngYk4wMBEHGBgIg4wMBEHGJiIAwxMxAEGJuIAAxNxgIGJOMDARBxgYCIOMDARBxiYiAMMTMQBBibi\nAANbKOJVdaSqLlTVxao6ucGYL1XVpap6tao+udxpArCeLSNeVQeSvJDkySQfT/J0VT2+ZsxTSR7p\n7o8lOZ7ky7dhrnBbzWaz3Z4CbNsiV+KHklzq7svdfT3JmSRH14w5muQrSdLdryS5p6oeWOpM4TYT\ncUa0SMQPJrmyavvq/L3NxlxbZwwAS+bGJsDA7lpgzLUkD63afnD+3toxH91iTJKkqrYzP7ijnn/+\n+d2eAmzLIhE/l+TRqno4yVtJjiV5es2Ys0k+m+RrVXU4yY+7++21B+puBQdYoi0j3t03qupEkpey\nsvxyurvPV9Xxld19qru/UVWfrqo3kvw0ybO3d9oAJEl1927PAYBb5MYmH3hVdbqq3q6q13Z7LrBd\nIg7Ji1l5mA2GI+J84HX3y0ne3e15wK0QcYCBiTjAwEQcYGAiDitq/gNDEXE+8Krqq0m+neSxqvph\nVXlYjWF42AdgYK7EAQYm4gADE3GAgYk4wMBEHGBgIg4wMBEHGJiIAwzs/wH+gNtp0FJ7xAAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f585c46db70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "V = 10000\n",
    "N = 400\n",
    "gamma_pi = (1, 1)\n",
    "gamma_theta = [1] * V\n",
    "lmbda = 25\n",
    "\n",
    "results = []\n",
    "cnt = 0\n",
    "while cnt < 10:\n",
    "    accuracy = run_simulation(V, N, gamma_pi, gamma_theta, lmbda)\n",
    "    results.append(accuracy)\n",
    "    cnt += 1\n",
    "    \n",
    "print(\"Accuracy results: %s\" % \", \".join(\"%0.3f\" % x for x in results))\n",
    "print(\"Average accuracy = %0.3f\" % np.average(results))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_ylim([0,1])\n",
    "plt.boxplot(results);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
